<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Rui Li, 李睿, Remote Sensing, Image Processing, Deep Learning, Segmentation, Wuhan University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Figs/favicon.ico">
<title>Rui Li</title>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable" style="margin-left:auto;margin-right:auto;"><tr><td>
<a href="./"><img src="./Figs/RL.jpg" alt="" height="215px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Rui Li (</font><font size="4"; font style="font-family:Microsoft YaHei">李 睿</font><font size="4">)</font></a><br />
<i> Ph.D. candidate </i>
<br /><br />
<a href="https://warwick.ac.uk/fac/sci/eng/" target="_blank">School of Engineering</a><br />
<a href="https://warwick.ac.uk/" target="_blank">University of Warwick</a><br />
<br />
<!-- Location: Building 5-Room 204, Luoyu Road #129, Hongshan District, Wuhan, Hubei, China<br /> -->
Location: Institute House, Sir William Lyons Rd, Coventry, UK<br />
<class="staffshortcut">
 <A HREF="#News">News</A> | 
 <A HREF="#Interest">Research Interest</A> | 
 <A HREF="#Education">Education</A> | 
 <A HREF="#Publications">Publications</A> | 
 <A HREF="#Services">Journal Reviewer</A> | 
 <A HREF="#Awards">Awards</A> | 
 <a href="https://lironui.github.io/Files/CV_RL.pdf" target="_blank">CV</a>
<br />
<br />
 
Email: lironui@whu.edu.cn (prior); &nbsp;&nbsp;&nbsp;&nbsp; lironui@163.com <br />
<!-- [<a href="./Files/CV.pdf" target="_blank">CV</a>] -->
[<img src="./Figs/google.png"  width="15" height="15"> <a href="https://scholar.google.com/citations?user=UFWyjxkAAAAJ" target="_blank">Google Scholar</a>] 
[<img src="./Figs/github.png"  width="15" height="15"> <a href="https://github.com/lironui" target="_blank">GitHub</a>] 
[<img src="./Figs/orcid.png"  width="15" height="15"> <a href="https://orcid.org/0000-0001-7858-3160" target="_blank">ORCID</a>]
[<img src="./Figs/researchgate.png"  width="15" height="15"> <a href="https://www.researchgate.net/profile/Li-Rui-49" target="_blank">ResearchGate</a>]
[<img src="./Figs/publons.png"  width="15" height="15"> <a href="https://publons.com/researcher/3378176/" target="_blank">Publons</a>]
[<img src="./Figs/linkedin.png"  width="15" height="15"> <a href="https://www.linkedin.com/in/rui-li-b93049251/" target="_blank">LinkedIn</a>]
</td></tr></table>


<A NAME="News"><h2>News</h2></A>
<ul>

<li> <b> <font color="#A569BD">[2022.11]</font> </b> One co-author paper is selected as an <b> ESI Highly Cited Paper (Top 1%)</b> 
<a href="https://ieeexplore.ieee.org/document/9681903" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" > </a>!</li>

<li> <b> <font color="#A569BD">[2022.10]</font> </b> One co-author paper is accepted by <b> IEEE GRSL </b> (<a href="https://ieeexplore.ieee.org/document/9921210/" target="_blank">link</a>) !</li>

<li> <b> <font color="#A569BD">[2022.08]</font> </b> One paper is accepted by <b> ECM </b> (<a href="https://www.sciencedirect.com/science/article/pii/S0196890422009633" target="_blank">link</a>) !</li>

<li> <b> <font color="#A569BD">[2022.07]</font> </b> One paper is accepted by <b> Energy </b> (<a href="https://www.sciencedirect.com/science/article/pii/S0360544222017480" target="_blank">link</a>, <a href="https://www.youtube.com/playlist?list=PLb_-O5lZoMkF1R0zLXNN_CDoZfB3Vd24Y" target="_blank">video</a>) !</li>

<li> <b> <font color="#A569BD">[2022.07]</font> </b> One paper is selected as an <b> ESI Highly Cited Paper (Top 1%)</b> 
<a href="https://www.tandfonline.com/doi/full/10.1080/10095020.2021.2017237" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" ></a> !</li>

<li> <b> <font color="#A569BD">[2022.06]</font> </b> One paper is accepted by <b> ECC 2022 </b> (<a href="https://ieeexplore.ieee.org/abstract/document/9838022" target="_blank">link</a>) !</li>

<li> <b> <font color="#A569BD">[2022.06]</font> </b> One co-author paper is accepted by <b> IEEE TGRS </b> (<a href="https://ieeexplore.ieee.org/document/9808187" target="_blank">link</a>, <a href="https://github.com/WangLibo1995/BuildFormer" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2022.06]</font> </b> One co-author paper is accepted by <b> ISPRS P&amp;RS </b> (<a href="https://www.sciencedirect.com/science/article/pii/S0924271622001654" target="_blank">link</a>, <a href="https://github.com/WangLibo1995/GeoSeg" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2022.05]</font> </b> One paper is selected as an <b> ESI Hot Paper (Top 0.1%)</b> 
<a href="https://www.sciencedirect.com/science/article/pii/S0924271621002379" target="_blank"><img src="./Figs/HP.png"  width="10.5" height="15"> </a>!</li>

<li> <b> <font color="#A569BD">[2022.05]</font> </b> Three papers are selected as <b> ESI Highly Cited Paper (Top 1%)</b> 
<a href="https://ieeexplore.ieee.org/document/9487010" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" > </a>
<a href="https://ieeexplore.ieee.org/document/9378788" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" > </a>
<a href="https://ieeexplore.ieee.org/document/9343296" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" > </a> !</li>

<li> <b> <font color="#A569BD">[2022.01]</font> </b> One paper is selected as an <b> ESI Highly Cited Paper (Top 1%)</b> 
<a href="https://www.mdpi.com/2072-4292/12/3/582" target="_blank"> <img src="./Figs/HCP.png"  width="11" height="15" > </a> !</li>

<li> <b> <font color="#A569BD">[2022.01]</font> </b> One co-author paper is accepted by <b> IEEE GRSL </b> (<a href="https://ieeexplore.ieee.org/document/9681903" target="_blank">link</a>) !</li>

<li> <b> <font color="#A569BD">[2022.01]</font> </b> One paper is accepted by <b> IJRS </b> (<a href="https://www.tandfonline.com/doi/full/10.1080/01431161.2022.2030071" target="_blank">link</a>, <a href="https://github.com/lironui/A2-FPN" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2021.12]</font> </b> One co-author paper is accepted by <b> RS </b> (<a href="https://www.mdpi.com/2072-4292/13/24/5015" target="_blank">link</a>) !</li>

<!-- <li> <b> <font color="#A569BD">[2021.11]</font> </b> 第六届“知卓”博士生论坛 <b> 专题报告 </b> (<a href="https://mp.weixin.qq.com/s/svBzVioco7xXMZg0CQ1p3g" target="_blank">link</a>, <a href="https://lironui.github.io/Files/zhizhuo.pdf" target="_blank">slides</a>)!</li> -->

<li> <b> <font color="#A569BD">[2021.11]</font> </b> One paper is accepted by <b> GSIS </b> (<a href="https://www.tandfonline.com/doi/full/10.1080/10095020.2021.2017237" target="_blank">link</a>, <a href="https://github.com/lironui/MSFCN" target="_blank">code</a>) !</li>

<!-- <li> <b> <font color="#A569BD">[2021.10]</font> </b> 首届《遥感学报》<b>青年学术论坛</b> 海报 (<a href="https://lironui.github.io/Files/LAmSS.pdf" target="_blank">poster</a>)!</li> -->

<li> <b> <font color="#A569BD">[2021.09]</font> </b> One paper is accepted by <b> ISPRS P&amp;RS </b> (<a href="https://www.sciencedirect.com/science/article/pii/S0924271621002379" target="_blank">link</a>, <a href="https://github.com/lironui/ABCNet" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2021.08]</font> </b> One corresponding author paper is accepted by <b>JGGS</b> (<a href="http://jggs.sinomaps.com/EN/10.11947/j.JGGS.2021.0404" target="_blank">link</a>, <a href="https://github.com/lironui/DDCD" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2021.07]</font> </b> One co-author paper is accepted by <b> RS </b> (<a href="https://www.mdpi.com/2072-4292/13/16/3065" target="_blank">link</a>, <a href="https://github.com/lironui/BANet" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2021.06]</font> </b> One paper is accepted by <b> IEEE TGRS </b> (<a href="https://ieeexplore.ieee.org/document/9487010" target="_blank">link</a>, <a href="https://github.com/lironui/Multi-Attention-Network" target="_blank">code</a>) !</li>
  
<li> <b> <font color="#A569BD">[2021.03]</font> </b> One paper is accepted by <b> IEEE GRSL </b> (<a href= "https://ieeexplore.ieee.org/document/9378788" target="_blank">link</a>, <a href= "https://github.com/lironui/MAResU-Net" target="_blank">code</a>) !</li>
  
<li> <b> <font color="#A569BD">[2021.01]</font> </b> One paper is accepted by <b> IEEE GRSL </b> (<a href= "https://ieeexplore.ieee.org/document/9343296" target="_blank">link</a>, <a href= "https://github.com/lironui/MACU-Net" target="_blank">code</a>) !</li>
  
<li> <b> <font color="#A569BD">[2020.10]</font> </b> Awarded with <b>The National Scholarship for Postgraduates </b> (<a href="http://newspace.rsgis.whu.edu.cn/show.php?contentid=7631" target="_blank"><font style="font-family:Microsoft YaHei">研究生国家奖学金</font></a>) !</li>
 
<li> <b> <font color="#A569BD">[2020.10]</font> </b> One co-author paper is accepted by <b> RS </b> (<a href= "https://www.mdpi.com/2072-4292/12/20/3446" target="_blank">link</a>) !</li>
 
<li> <b> <font color="#A569BD">[2020.02]</font> </b> One paper is accepted by <b>RS</b> (<a href= "https://www.mdpi.com/2072-4292/12/3/582" target="_blank">link</a>, <a href= "https://github.com/lironui/Double-Branch-Dual-Attention-Mechanism-Network" target="_blank">code</a>) !</li>

<li> <b> <font color="#A569BD">[2019.11]</font> </b> One paper is accepted by <b> 计算机应用研究 </b> (<a href= "https://www.arocmag.com/article/01-2020-11-002.html" target="_blank">link</a>) !</li> 

</ul>
<br />

<A NAME="Interest"><h2>Research Interest</h2></A>
<p style="padding-left: 0.5rem;margin-left: -0.5rem;", align="justify">
My research interests lie in trans-disciplinary applications of deep learning methods, especially for image processing, computer vision and renewable energy. I have authored more than <b> 15 </b> peer-reviewed articles in international scientific journals such as <b>ISPRS P&amp;RS</b> (IF=<b><font color="#A569BD">11.774</font></b>), <b>IEEE TGRS</b> (IF=<b><font color="#A569BD">8.125</font></b>), <b>ECM</b> (IF=<b><font color="#A569BD">11.533</font></b>) and <b>Energy</b> (IF=<b><font color="#A569BD">8.857</font></b>), which have been cited <b> <font color="#A569BD">200+</font></b> times indexed by the Web of Science with the <i>h</i>-index of <b><font color="#A569BD">9</font></b>. <b>Five</b> of my first-authored papers have been selected as the <img src="./Figs/HCP.png" width="11" height="15" ><b><font color="#A569BD"> ESI Highly Cited Paper </font></b>(<b>Top 1%</b>) and <b>one</b> as the <img src="./Figs/HP.png"  width="11" height="15" > <b> <font color="#A569BD"> ESI Hot Paper</font></b> (<b>Top 0.1%</b>). Currently, my research topics include:
</p>
<ul>
<li>Deep Learning for Semantic Segmentation</li>
<li>Land Cover and Land Use Classification</li>
<li>Attention Mechanism in Deep Learning</li>
<li>Transformer for Computer Vision</li>
<li>Thick and Thin Cloud Removal</li>
<li>Offshore Renewable Energy</li>
</ul>
<br />

<A NAME="Education"><h2>Education</h2></A>
<ul>

<li>2021.10-Now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D. candidate in <a href="https://warwick.ac.uk/fac/sci/eng/" target="_blank">School of Engineering</a>, <a href="https://warwick.ac.uk/" target="_blank">University of Warwick</a></li>
<li>2019.09-2021.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; M.E. in <a href="http://rsgis.whu.edu.cn/" target="_blank">School of Remote Sensing and Information Engineering</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a></li>
<li>2015.09-2019.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.E. in <a href="http://www2.scut.edu.cn/automation/" target="_blank">School of Automation Science and Engineering</a>, <a href="https://www.scut.edu.cn/new/" target="_blank">South China University of Technology</a></li>
</ul>
<br />



<A NAME="Publications"><h2>Publications</h2></A>
<!-- <p><b>Journals</b>: </p>
<font size="3"> 
<ul> -->

<p><b>Wind Farm Wake Modeling</b>: </p>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/SFNet.jpg" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.sciencedirect.com/science/article/pii/S0196890422009633" style="color:rgb(0,0,0);">Multi-Fidelity Modeling of Wind Farm Wakes Based on A Novel Super-Fidelity Network</a></b><br>
<u>R. Li</u>, J. Zhang and X. Zhao.<br>
<i>Energy Conversion and Management</i> (SCI Q1 Top, IF=<b><font color="#A569BD">11.533</font></b>)<br>
[<a href="https://www.sciencedirect.com/science/article/pii/S0196890422009633" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/SFNet.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#LI2022116185" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/BiCNN.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.sciencedirect.com/science/article/pii/S0360544222017480" style="color:rgb(0,0,0);">Dynamic Wind Farm Wake Modeling Based on a Bilateral Convolutional Neural Network and High-Fidelity LES Data</a></b><br>
<u>R. Li</u>, J. Zhang and X. Zhao.<br> 
<i>Energy</i> (SCI Q1 Top, IF=<b><font color="#A569BD">8.857</font></b>)<br>
[<a href="https://www.sciencedirect.com/science/article/pii/S0360544222017480" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/BiCNN.pdf" target="_blank">PDF</a>]
[<a href="https://www.youtube.com/playlist?list=PLb_-O5lZoMkF1R0zLXNN_CDoZfB3Vd24Y" target="_blank">Video</a>]
[<a href="./Files/BibTex.html#li202184" target="_blank">BibTeX</a>]</td></tr>
</table>

<p><b>Attention Mechanism</i>: </b>
<font size="3"> 
<table class="imgtable">
<tr><td><img src="./Figs/ABCNet.png" width="250" height="120"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.sciencedirect.com/science/article/pii/S0924271621002379" style="color:rgb(0,0,0);">ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images</a></b> <br>
<u>R. Li</u>, S. Zheng, C. Zheng, C. Duan, L. Wang and P. M. Atkinson.<br> 
ISPRS <i> Journal of Photogrammetry and Remote Sensing </i>(SCI Q1 Top, IF=<b><font color="#A569BD">11.774</font></b>)<br>
[<a href="https://www.sciencedirect.com/science/article/pii/S0924271621002379" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/ABCNet.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/ABCNet" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#li202184" target="_blank">BibTeX</a>]
[ <img src="./Figs/HP.png"  width="10.5" height="15"> Citations: <b>20</b>+]</td></tr> <! ---2022.5-2022.7 --->
</table>

<table class="imgtable">
<tr><td><img src="./Figs/MANet.png" width="250" height="120"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9487010" style="color:rgb(0,0,0);">Multiattention-Network for Semantic Segmentation of Fine-Resolution Remote Sensing Images</a></b> <br>
<u>R. Li</u>, S. Zheng, C. Zhang, C. Duan, J. Su, L. Wang and P. M. Atkinson.<br> 
IEEE <i>Transactions on Geoscience and Remote Sensing</i> (SCI Q2 Top, IF=<b><font color="#A569BD">8.125</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9487010" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/MANet.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/Multi-Attention-Network" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#9808187" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>35</b>+] <!--since 2022.5 --->
</table>

<table class="imgtable">
<tr><td><img src="./Figs/MAResUNet.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9378788" style="color:rgb(0,0,0);">Multistage Attention ResU-Net for Semantic Segmentation of Fine-Resolution Remote Sensing Images</a> </b> <br>
<u>R. Li </u> *, S. Zheng, C. Duan, J. Su and C. Zhang.<br> 
IEEE <i>Geoscience and Remote Sensing Letters</i> (SCI Q2, IF=<b><font color="#A569BD">5.343</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9378788" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/MAResU-Net.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/MAResU-Net" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#li2021multistage" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>20</b>+]</td></tr> <!-- 2022.5-2022.9 --->
</table>

<p><b>Vision Transformer</i>: </b>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/UNetFormer.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.sciencedirect.com/science/article/pii/S0924271622001654" style="color:rgb(0,0,0);">UNetFormer: An UNet-like Transformer for Efficient Semantic Segmentation of Remote Sensing Urban Scene Imagery</a></b> <br>
L. Wang, <u>R. Li</u>, C. Zheng, S. Fang, C. Duan, X. Meng and P. M. Atkinson.<br> 
ISPRS <i> Journal of Photogrammetry and Remote Sensing </i>(SCI Q1 Top, IF=<b><font color="#A569BD">11.774</font></b>)<br>
[<a href="https://www.sciencedirect.com/science/article/pii/S0924271622001654" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/UNetFormer.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/WangLibo1995/GeoSeg" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#WANG2022196" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/BuildFormer.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9808187" style="color:rgb(0,0,0);">Building Extraction with Vision Transformer</a></b> <br>
L. Wang, S. Fang, and X. Meng and <u>R. Li</u>.<br> 
IEEE <i>Transactions on Geoscience and Remote Sensing</i> (SCI Q2 Top, IF=<b><font color="#A569BD">8.125</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9808187" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/BuildFormer.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/WangLibo1995/BuildFormer" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#li202184" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/DCSwin.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9681903" style="color:rgb(0,0,0);">A Novel Transformer based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images</a> </b> <br>
L. Wang, <u>R. Li</u>, C. Duan, C. Zhang, X. Meng and S. Fang.<br> 
IEEE <i>Geoscience and Remote Sensing Letters</i> (SCI Q2, IF=<b><font color="#A569BD">5.343</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9681903" target="_blank">Link</a>]
[<a href="https://lironui.github.io/Files/DC-Swin.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#wang9681903" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>15</b>+]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/BANet.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.mdpi.com/2072-4292/13/16/3065" style="color:rgb(0,0,0);">Transformer Meets Convolution: A Bilateral Awareness Network for Semantic Segmentation of Very Fine Resolution Urban Scene Images</a> </b> <br>
L. Wang †, <u>R. Li</u> †, D. Wang, C. Duan, T. Wang and X. Meng.<br> 
<i>Remote Sensing</i> (SCI Q2 Top, IF=<b><font color="#A569BD">5.349</font></b>)<br>
[<a href="https://www.mdpi.com/2072-4292/13/16/3065" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/BANet.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/BANet" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#wang2021transformer" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/CGSwin.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9921210" style="color:rgb(0,0,0);">Class-Guided Swin Transformer for Semantic Segmentation of Remote Sensing Imagery</a> </b> <br>
X. Meng †, Y. Yang †, L. Wang, T. Wang, <u>R. Li</u> and C. Zhang.<br> 
IEEE <i>Geoscience and Remote Sensing Letters</i> (SCI Q2, IF=<b><font color="#A569BD">5.343</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9921210" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/CG-Swin.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#9921210" target="_blank">BibTeX</a>]</td></tr>
</table>


<p><b>Semantic Segmentation</b>: </p>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/A2FPN.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.tandfonline.com/doi/full/10.1080/01431161.2022.2030071" style="color:rgb(0,0,0);">A<sup>2</sup>-FPN for Semantic Segmentation of Fine-Resolution Remotely Sensed Images</a> </b> <br>
<u>R. Li</u>, L. Wang, C. Zhang, C. Duan and S. Zheng.<br> 
<i>International Journal of Remote Sensing</i> (SCI Q3, IF=<b><font color="#A569BD">3.531</font></b>)<br>
[<a href="https://www.tandfonline.com/doi/full/10.1080/01431161.2022.2030071" target="_blank">Link</a>]
[<a href="https://lironui.github.io/Files/A2-FPN.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/A2-FPN" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#doi:10.1080/01431161.2022.2030071" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/MSFCN.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.tandfonline.com/doi/full/10.1080/10095020.2021.2017237" style="color:rgb(0,0,0);">Land Cover Classification from Remote Sensing Images Based on Multi-Scale Fully Convolutional Network</a> </b> <br>
<u>R. Li</u>, S. Zheng, C. Duan, L. Wang and C. Zhang.<br> 
<i> Geo-spatial Information Science </i> (SCI Q3, IF=<b><font color="#A569BD">4.278</font></b>)<br>
[<a href="https://www.tandfonline.com/doi/full/10.1080/10095020.2021.2017237" target="_blank">Link</a>]
[<a href="https://lironui.github.io/Files/MSFCN.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/lironui/MSFCN" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#ruiland" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>10</b>+]</td></tr> <!--since 2022.7 ---><br>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/MACUNet.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/document/9343296" style="color:rgb(0,0,0);">MACU-Net for Semantic Segmentation of Fine-Resolution Remotely Sensed Images</a> </b> <br>
<u>R. Li</u> †*, C. Duan †, S. Zheng, C. Zhang and P. M. Atkinson.<br> 
IEEE <i>Geoscience and Remote Sensing Letters</i> (SCI Q2, IF=<b><font color="#A569BD">5.343</font></b>)<br>
[<a href="https://ieeexplore.ieee.org/document/9343296" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/MACU-Net.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/MACU-Net" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#li2021macu" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>20</b>+]</td></tr> <!--since 2022.5 --->
</table>

<table class="imgtable">
<tr><td><img src="./Figs/SANet.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.mdpi.com/2072-4292/13/24/5015" style="color:rgb(0,0,0);">Scale-Aware Neural Network for Semantic Segmentation of Multi-resolution Remote Sensing Images</a> </b> <br>
L. Wang, C. Zhang, <u>R. Li</u>, C. Duan, X. Meng and P. M. Atkinson.<br> 
<i>Remote Sensing</i> (SCI Q2 Top, IF=<b><font color="#A569BD">5.349</font></b>)<br>
[<a href="https://www.mdpi.com/2072-4292/13/24/5015" target="_blank">Link</a>]
[<a href="https://lironui.github.io/Files/SaNet.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#rs13245015" target="_blank">BibTeX</a>]</td></tr>
</table>

<p><b>Hyperspectral Image Classification</b>: </p>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/DBDA.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.mdpi.com/2072-4292/12/3/582" style="color:rgb(0,0,0);">Classification of Hyperspectral Image Based on Double-Branch Dual-Attention Mechanism Network</a> </b> <br>
<u>R. Li</u> *, S. Zheng, C. Duan, Y. Yang and X. Wang.<br> 
<i>Remote Sensing</i><b> (SCI Q2 Top, IF=<font color="#A569BD">4.848</font></b>)<br>
[<a href="https://www.mdpi.com/2072-4292/12/3/582" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/DBDA.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/Double-Branch-Dual-Attention-Mechanism-Network" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#li2020classification" target="_blank">BibTeX</a>]
[ <img src="./Figs/HCP.png"  width="10.5" height="15"> Citations: <b>100</b>+]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/DDCD.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="http://jggs.chinasmp.com/EN/10.11947/j.JGGS.2021.0404" style="color:rgb(0,0,0);">A Deep Double-Channel Dense Network for Hyperspectral Image Classification </a> </b> <br>
K. Wang, S. Zheng, <u>R. Li</u> * and L. Gui. <br> 
<i>Journal of Geodesy and Geoinformation Science</i> 测绘学报英文版<br>
[<a href="http://jggs.chinasmp.com/EN/10.11947/j.JGGS.2021.0404" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/DDCD.pdf" target="_blank">PDF</a>]
[<a href="https://github.com/lironui/DDCD" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#wangdeep" target="_blank">BibTeX</a>]</td></tr>
</table>

<p><b>Cloud Removal</i>: </b>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/TSSTO.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.mdpi.com/2072-4292/12/20/3446" style="color:rgb(0,0,0);">Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness and Sparsity Regularized Tensor Optimization</a> </b> <br>
C. Duan, J. Pan and <u>R. Li</u>. <br> 
<i>Remote Sensing</i> (SCI Q2 Top, IF=<b><font color="#A569BD">4.848</font></b>)<br>
[<a href="https://www.mdpi.com/2072-4292/12/20/3446" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/Thick_Cloud_Removal.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#duan2020thick" target="_blank">BibTeX</a>]</td></tr>
</table>

<p><b>Others</i>: </b>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/RYOLO.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.mdpi.com/1424-8220/21/3/888" style="color:rgb(0,0,0);">R-YOLO: A Real-Time Text Detector for Natural Scenes with Arbitrary Rotation</a> </b> <br>
[2] X. Wang, S. Zheng, C. Zhang <u>R. Li</u> and L. Gui.<br> 
<i>Sensors</i>(SCI Q3, IF= <b><font color="#A569BD">3.847</font></b>)<br>
[<a href="https://www.mdpi.com/1424-8220/21/3/888" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/R-YOLO.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#wang2021r" target="_blank">BibTeX</a>]</td></tr>
</table>

<table class="imgtable">
<tr><td><img src="./Figs/review.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://www.arocmag.com/article/01-2020-11-002.html" style="color:rgb(0,0,0);">视觉—语言—行为:视觉语言融合研究综述</a> </b> <br>
<u>李睿</u>, 郑顺义, 王西旗.<br> 
<i> 计算机应用研究 </i> (中文核心, IF=<b><font color="#A569BD">1.140</font></b>)<br>
[<a href="https://www.arocmag.com/article/01-2020-11-002.html" target="_blank">Link</a>] 
[<a href="https://lironui.github.io/Files/视觉语言行为.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#李睿、郑顺义、王西旗2020视觉—语言—行为" target="_blank">BibTeX</a>]</td></tr>
</table>

<br><br><br>
<p><b>Conference</i>: </b>
<font size="3"> 

<table class="imgtable">
<tr><td><img src="./Figs/WindFormer.png" width="250" height="100"></td>
<td height="92" style="text-align:justify;">
<b><a href="https://ieeexplore.ieee.org/abstract/document/9838022" style="color:rgb(0,0,0);">Deep Learning-based Wind Farm Power Prediction using Transformer Network</a> </b> <br>
<u>R. Li</u>, J. Zhang and X. Zhao.<br> 
2022 <i> European Control Conference </i><b> <font color="#A569BD">(EI, Oral)</font></b><br>
[<a href= "https://ieeexplore.ieee.org/abstract/document/9838022" target="_blank">Link</a>] 
[<a href= "https://lironui.github.io/Files/WiT.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#9838022" target="_blank">BibTeX</a>]</td></tr>
</table>

</span>
<br />
† Equal Contribution &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * Corresponding Author &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src="./Figs/HCP.png"  width="11" height="15"> ESI Highly Cited Paper &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src="./Figs/HP.png"  width="11" height="15"> ESI Hot Paper 
</p>
</ul>
</font>
<br />



<A NAME="Services"><h2>Journal Reviewer</h2></A>
 
<!-- <p><b>Journal Reviewer</b>: </p>  -->
<font size="3"> 
<ul>
<li>IEEE Transactions on Medical Imaging</li>
<li>IEEE Transactions on Geoscience and Remote Sensing</li>
<li>IEEE Geoscience and Remote Sensing Letters</li>
<li>Engineering Applications of Artificial Intelligence</li>
<li>GIScience & Remote Sensing</li>
<li>Geo-spatial Information Science</li>
<li>International Journal of Remote Sensing</li>
<li>Geocarto International</li>
<li>Journal of Applied Remote Sensing</li>
<li>Journal of Electronic Imaging</li>
<li>Imaging Science Journal</li>
</ul>
</font>
<br />

<!-- 
<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>IEEE Member, 2021-Now</li>
<li>IEEE Geoscience and Remote Sensing Society (GRSS), Student Member, 2021-Now</li>
</ul>
</font>
<br />
 -->



<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2021, Outstanding Postgraduates, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀毕业生</font></li>
<li>2020, National Scholarship for Postgraduate Student, Ministry of Education | <font style="font-family:Microsoft YaHei">研究生国家奖学金</font></li>
<li>2020, First Class Postgraduate Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学一等学业奖学金</font></li>
<li>2017 & 2018, National Encouragement Scholarship, Ministry of Education | <font style="font-family:Microsoft YaHei">国家励志奖学金</font></li>
<li>2016 & 2017, Merit Student, South China University of Technology | <font style="font-family:Microsoft YaHei">华南理工大学三好学生</font></li>


</ul>
</font>
 
<br />
<br />


<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=526kylnmz0i&amp;m=7&amp;c=00fff6&amp;cr1=baff00&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
 

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


<!--
All Rights Reserved by Qiang Zhang. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->
